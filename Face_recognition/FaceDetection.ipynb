{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mtcnn\n",
      "  Downloading mtcnn-0.1.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: keras>=2.0.0 in /Users/nizarsmac/anaconda3/lib/python3.11/site-packages (from mtcnn) (2.15.0)\n",
      "Collecting opencv-python>=4.1.0 (from mtcnn)\n",
      "  Using cached opencv_python-4.9.0.80-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/nizarsmac/anaconda3/lib/python3.11/site-packages (from opencv-python>=4.1.0->mtcnn) (1.26.4)\n",
      "Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hUsing cached opencv_python-4.9.0.80-cp37-abi3-macosx_11_0_arm64.whl (35.4 MB)\n",
      "Installing collected packages: opencv-python, mtcnn\n",
      "Successfully installed mtcnn-0.1.1 opencv-python-4.9.0.80\n"
     ]
    }
   ],
   "source": [
    "!pip install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "from mtcnn.mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faceDetectionViolaJones(img):\n",
    "\n",
    "    #Exercise 1 - The faceDetectionViolaJones method receives as input an image and returns the bounding boxes\n",
    "    #of all the detected faces\n",
    "    bboxes = []\n",
    "\n",
    "    #TODO - Exercise 1 - Convert the image to a grayscale image\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #TODO - Exercise 1 - Load the pre-trained cascade classifier model called haarcascade_frontalface_default.xml\n",
    "    classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    #TODO - Exercise 1 - Perform face detection using the default parameters (scaleFactor = 1.1, minNeighbors = 3)\n",
    "    faces_rect = classifier.detectMultiScale(gray_img, scaleFactor = 1.1, minNeighbors = 3)\n",
    "\n",
    "    #TODO - Exercise 1 - ViolaJones detector returns bounding boxes as [x1, y1, w, h].\n",
    "    # Convert them to a format [x1, y1, x2, y2]\n",
    "    for (x1, y1, w, h) in faces_rect:\n",
    "        x2 = x1 + w\n",
    "        y2 = y1 + h\n",
    "        bboxes.append([x1, y1, x2, y2])\n",
    "\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawDetectedFaces(img, bboxes):\n",
    "\n",
    "    #Exercise 2 - Draw a bounding box for each detected face on the image\n",
    "    for (x1, y1, x2, y2) in bboxes:\n",
    "\n",
    "        #TODO - Exercices 2 - Draw a rectangle over the image img\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "        #DELETE THIS after you write the code in the for loop\n",
    "        continue\n",
    "\n",
    "    #TODO - Exercise 2 - Display the marked image\n",
    "    cv2.imshow('Detected Faces', img)\n",
    "\n",
    "    #TODO - Exercise 2 - Keep the window open until we press a key\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    #TODO - Exercise 2 - Close the window\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIntersectionOverUnion(box, box_GT):\n",
    "\n",
    "    #Exercise 3 - Step 3 - This function computes the intersection over union score (iou)\n",
    "    iou = 0\n",
    "\n",
    "    #TODO - Exercise 3 - Step 3 - Compute the rectangle resulted by the intersection of the two bounding boxes\n",
    "    # This should be specified in the following format [x1, y1, x2, y2]\n",
    "    xA = max(box[0], box_GT[0])\n",
    "    yA = max(box[1], box_GT[1])\n",
    "    xB = min(box[2], box_GT[2])\n",
    "    yB = min(box[3], box_GT[3])\n",
    "    rectInters = [xA, yA, xB, yB]\n",
    "\n",
    "    #TODO - Exercise 3 - Step 3 - Compute the area of rectInters (rectIntersArea)\n",
    "    rectIntersArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "    \n",
    "    #TODO - Exercise 3 - Step 3 - Compute the area of the box (boxArea)\n",
    "    boxArea = (box[2] - box[0]) * (box[3] - box[1])\n",
    "\n",
    "    #TODO - Exercise 3 - Step 3 - Compute the area of the box_GT (boxGTArea)\n",
    "    boxGTArea = (box_GT[2] - box_GT[0]) * (box_GT[3] - box_GT[1])\n",
    "\n",
    "    #TODO - Exercise 3 - Step3 - Compute the union area (unionArea) of the two boxes\n",
    "    unionArea = boxArea + boxGTArea - rectIntersArea\n",
    "\n",
    "    #TODO - Exercise 3 - Step 3 - Compute the intersection over union score (iou)\n",
    "    if unionArea > 0:\n",
    "        iou = rectIntersArea / unionArea\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareAgainstGT(imgf, bboxes):\n",
    "\n",
    "    #Exercise 3 - This function compare the list of detected faces against the ground truth\n",
    "    d_faces = 0         #the number of correctly detected faces\n",
    "    md_faces = 0        #the number of missed detected faces\n",
    "    fa = 0              #the number of false alarms\n",
    "    bboxes_GT = []\n",
    "\n",
    "    #TODO - Exercise 3 - Step 1 - Open the file with the ground truth for the associated image (imgf)\n",
    "    # and read its content\n",
    "    gt_file_name = imgf.replace('.jpg', '.txt')  # Assuming ground truth file has same name but .txt extension\n",
    "\n",
    "    #TODO - Exercise 3 - Step 2 - Save the bounding boxes parsed from the GT file into the bboxes_GT list\n",
    "    with open(gt_file_name, 'r') as file:\n",
    "        for line in file:\n",
    "            # Remove whitespace characters like “\\n” at the end of each line\n",
    "            line = line.strip()\n",
    "            # Convert string to list of integers\n",
    "            bbox = list(map(int, line.split()))\n",
    "            if bbox:  # If bbox is not empty\n",
    "                bboxes_GT.append(bbox)\n",
    "\n",
    "    #TODO - Exercise 3 - Step 4 - Perform the validation of the bboxes (detected automatically)\n",
    "    # against the bboxes_GT (annotated manually). In order to verify if two bounding boxes overlap it is necessary\n",
    "    # to define another function denoted \"computeIntersectionOverUnion(box, box_GT)\"\n",
    "    for box in bboxes:\n",
    "        match_found = False\n",
    "        for box_GT in bboxes_GT:\n",
    "            iou = computeIntersectionOverUnion(box, box_GT)\n",
    "            if iou > 0.2:  # Using a threshold of 0.2 as an example\n",
    "                d_faces += 1\n",
    "                match_found = True\n",
    "                break\n",
    "        if not match_found:\n",
    "            fa += 1\n",
    "            \n",
    "    # Any ground truth box not matched is considered a missed detection\n",
    "    md_faces = len(bboxes_GT) - d_faces\n",
    "\n",
    "    #Exercise 3 - Display the scores\n",
    "    print(\"The scores for image {} are:\".format(imgf))\n",
    "    print(\"   - The number of correctly detected faces: {}\".format(d_faces))\n",
    "    print(\"   - The number of missed detected faces: {}\".format(md_faces))\n",
    "    print(\"   - The number of false alarms: {}\".format(fa))\n",
    "\n",
    "    return d_faces, md_faces, fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faceDetectionMTCNN(img):\n",
    "\n",
    "    # Exercise 4 - The faceDetectionMTCNN method receives as input an image\n",
    "    # and returns the bounding boxes of all the detected faces\n",
    "    bboxes = []\n",
    "\n",
    "    #TODO - Exercise 4 - Convert the image from BGR to RGB\n",
    "\n",
    "    #TODO - Exercise 4 - Create the detector, using the default weights\n",
    "\n",
    "    #TODO - Exercise 4 - Detect faces in the image\n",
    "\n",
    "    #TODO - Exercise 4 - Save all the faces bounding boxes in the bboxes list\n",
    "\n",
    "    #TODO - Exercise 4 - MTCNN detector returns bounding boxes as [x1, y1, w, h].\n",
    "    # Convert them to a format [x1, y1, x2, y2]\n",
    "\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # Read images from GT_FaceImages directory\n",
    "    imgfiles = glob.glob(\"./GT_FaceImages/*.jpg\")\n",
    "    for imgf in imgfiles:\n",
    "        img = cv2.imread(imgf)\n",
    "\n",
    "        #TODO - Exercise 1 - Call the faceDetectionViolaJones method OR Exercise 4 - Call the faceDetectionMTCNN method\n",
    "        bboxes = faceDetectionViolaJones(img)\n",
    "\n",
    "        #TODO - Exercise 2 - Call the drawDetectedFaces method\n",
    "        drawDetectedFaces(img, bboxes)\n",
    "\n",
    "        #TODO - Exercise 3 - Call the compareAgainstGT method\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
